{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация данных и оценка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Валидация данных. Методы валидации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу классификации: классифицировать воду на пригодную и не пригодную для питья на основе её химического состава."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импортируем необходимые модули\n",
    "\n",
    "#Для матричных вычислений\n",
    "import numpy as np \n",
    "#Для анализа и предобработки данных\n",
    "import pandas as pd\n",
    "#Для визуализации\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#Метрики\n",
    "from sklearn import metrics\n",
    "#Методы разделения и валидации\n",
    "from sklearn import model_selection\n",
    "\n",
    "#Линейные модели \n",
    "from sklearn import linear_model\n",
    "#Деревья решений\n",
    "from sklearn import tree\n",
    "#Стиль отрисовки seaborn \n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Загрузим наши данные\n",
    "water_data = pd.read_csv('data/water_potability.csv')\n",
    "display(water_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 14.987790\n",
       "Hardness            0.000000\n",
       "Solids              0.000000\n",
       "Chloramines         0.000000\n",
       "Sulfate            23.840049\n",
       "Conductivity        0.000000\n",
       "Organic_carbon      0.000000\n",
       "Trihalomethanes     4.945055\n",
       "Turbidity           0.000000\n",
       "Potability          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Выведем информацию о пропусках в данных в процентном соотношении\n",
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполняем пропуски\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')\n",
    "                                           ['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')\n",
    "                                           ['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')\n",
    "                                           ['Trihalomethanes'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0.0\n",
       "Hardness           0.0\n",
       "Solids             0.0\n",
       "Chloramines        0.0\n",
       "Sulfate            0.0\n",
       "Conductivity       0.0\n",
       "Organic_carbon     0.0\n",
       "Trihalomethanes    0.0\n",
       "Turbidity          0.0\n",
       "Potability         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Убедимся в отсутствии пропусков\n",
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим набор данных на матрицу наблюдений \n",
    "#и вектор правильных ответов\n",
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные методы валидации данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOLD-OUT\n",
    "Его идея состоит в том, что для проверки модели мы просто случайным образом разбиваем весь набор данных на обучающую, валидационную и тестовую выборки (последняя — по желанию).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация метода в sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пример разбиения данных\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, \n",
    "                                                                      y, \n",
    "                                                                      test_size=0.2,\n",
    "                                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Test shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "#Проверим размеры полученных выборок\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Test shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели будем использовать дерево решений с максимальной глубиной 7, энтропией в качестве критерия информативности, минимальное число объектов в листе дерева — 5.\n",
    "\n",
    "После обучения сделаем предсказание для каждой из выборок и рассчитаем метрику. В качестве метрики для простоты возьмём долю правильных ответов — accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Создаем модель \n",
    "model = tree.DecisionTreeClassifier(\n",
    "    #Критерий информативности\n",
    "    criterion='entropy',\n",
    "    #Максимальная глубина\n",
    "    max_depth=7,\n",
    "    #Минимальное число объектов в листе\n",
    "    min_samples_leaf=5,\n",
    "    #Генератор случайных чисел\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Делаем предсказание на каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "#Выводим значение метрик\n",
    "print('Train hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_train, y_train_pred)))\n",
    "print('Valid hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же мы используем трёхкомпонентный подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), нам понадобится чуть больше кода. К сожалению, в sklearn нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию train_test_split() дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении 80/20, затем разобьём валидационный набор на валидационный и тестовый в соотношении 50/50. В итоге наша выборка будет разбита в соотношении 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2,\n",
    "                                                                      random_state=42)\n",
    "#Разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5,\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (328, 9)\n",
      "Test shape: (328, 9)\n"
     ]
    }
   ],
   "source": [
    "#Выводим размерности \n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-FOLD\n",
    "Реализация метода в sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    #Критерий информативности\n",
    "    criterion='entropy',\n",
    "    #Максимальная глубина \n",
    "    max_depth=7,\n",
    "    #Минимальное число объектов в листе\n",
    "    min_samples_leaf=5,\n",
    "    #Генератор случайных чисел\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Создаем объект кросс-валидации KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "#Создаем список хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "#Организуем цикл для кросс валидации (используем весь набор данных)\n",
    "#train_index - индексы тренировочный выборки\n",
    "#valid_index - индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "\n",
    "    #Обучаем дерево решений на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    #Рассчитываем метрику и заносим ее в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
      "[0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]\n"
     ]
    }
   ],
   "source": [
    "#Выведем содержимое массивов train_metrics и val_metrics\n",
    "print(train_metrics)\n",
    "print(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "#Для агрегированной оценки рассчитаем среднее значение метрик\n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(train_metrics)))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(val_metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.027004  , 0.02300334, 0.02400184, 0.02900696, 0.03000307]),\n",
       " 'score_time': array([0.0020051 , 0.00200415, 0.00300503, 0.00300288, 0.00200319]),\n",
       " 'test_score': array([0.79573171, 0.70534351, 0.73587786, 0.72824427, 0.73282443]),\n",
       " 'train_score': array([0.80343511, 0.81686379, 0.80274704, 0.82678367, 0.81571919])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Итоговый код с использованием функции cross_validate()\n",
    "\n",
    "#Создаем модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    #Критерий информативности\n",
    "    criterion='entropy',\n",
    "    #Максимальная глубина \n",
    "    max_depth=7,\n",
    "    #Минимальное число объектов в листе\n",
    "    min_samples_leaf=5,\n",
    "    #Генератор случайных чисел\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Создаем объект кросс-валидации KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "\n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    #Модель\n",
    "    estimator=model,\n",
    "    #Матрица наблюдений X\n",
    "    X=X,\n",
    "    #Вектор ответов y\n",
    "    y=y,\n",
    "    #Кросс-валидатор\n",
    "    cv=kf,\n",
    "    #Метрика\n",
    "    scoring='accuracy',\n",
    "    #Подсчет метрики на тренировочных фолдах\n",
    "    return_train_score=True\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "#Рассчитаем среднее значение\n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAVE-ONE-OUT\n",
    "Реализация метода в sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как датасет у нас довольно большой (более трёх тысяч образцов воды), алгоритм кросс-валидации leave-one-out будет выполняться очень долго. Для экономии времени выполнения кода будем использовать первые 500 наблюдений из исходной таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.95\n",
      "Valid k-fold mean accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "#Создаем модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    #Критерий информативности\n",
    "    criterion='entropy',\n",
    "    #Максимальная глубина \n",
    "    max_depth=7,\n",
    "    #Минимальное число объектов в листе\n",
    "    min_samples_leaf=5,\n",
    "    #Генератор случайных чисел\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Создаем объект кросс-валидации KFold\n",
    "loo = model_selection.LeaveOneOut()\n",
    "\n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    #Модель\n",
    "    estimator=model,\n",
    "    #Матрица наблюдений X\n",
    "    X=X.iloc[:500],\n",
    "    #Вектор ответов y\n",
    "    y=y.iloc[:500],\n",
    "    #Кросс-валидатор\n",
    "    cv=loo,\n",
    "    #Метрика\n",
    "    scoring='accuracy',\n",
    "    #Подсчет метрики на тренировочных фолдах\n",
    "    return_train_score=True\n",
    ")\n",
    "#Рассчитаем среднее значение\n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "#Сделаем тоже самое, но не будем срезать данные\n",
    "#Создаем модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    #Критерий информативности\n",
    "    criterion='entropy',\n",
    "    #Максимальная глубина \n",
    "    max_depth=7,\n",
    "    #Минимальное число объектов в листе\n",
    "    min_samples_leaf=5,\n",
    "    #Генератор случайных чисел\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Создаем объект кросс-валидации KFold\n",
    "loo = model_selection.LeaveOneOut()\n",
    "\n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    #Модель\n",
    "    estimator=model,\n",
    "    #Матрица наблюдений X\n",
    "    X=X,\n",
    "    #Вектор ответов y\n",
    "    y=y,\n",
    "    #Кросс-валидатор\n",
    "    cv=loo,\n",
    "    #Метрика\n",
    "    scoring='accuracy',\n",
    "    #Подсчет метрики на тренировочных фолдах\n",
    "    return_train_score=True\n",
    ")\n",
    "#Рассчитаем среднее значение\n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
